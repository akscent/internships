{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers --upgrade >> installations.log","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-17T23:20:41.161458Z","iopub.execute_input":"2023-04-17T23:20:41.162229Z","iopub.status.idle":"2023-04-17T23:21:05.264532Z","shell.execute_reply.started":"2023-04-17T23:20:41.162190Z","shell.execute_reply":"2023-04-17T23:21:05.263331Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric\nsquad_v2 = False\nmodel_checkpoint = \"distilbert-base-uncased\"\nbatch_size = 16\ndatasets = load_dataset(\"squad_v2\" if squad_v2 else \"squad\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T23:26:28.153543Z","iopub.execute_input":"2023-04-17T23:26:28.154748Z","iopub.status.idle":"2023-04-17T23:26:43.397625Z","shell.execute_reply.started":"2023-04-17T23:26:28.154643Z","shell.execute_reply":"2023-04-17T23:26:43.396301Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"432304aac9914f08a16c4365fc650885"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3bbfeaf925f400681267acc32eedce3"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.63 MiB, post-processed: Unknown size, total: 119.14 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb422c1acabb41979eb59926b7827e50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/8.12M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1175c6dcf22d434a8d593789fc56015a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.05M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6781197d5876424491be8b17f0997907"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22b200512e714d5b97d81db4c9016c67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f33db4ff2364d7ca41fff9096d925d4"}},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset, DatasetDict\n\n\nclass QADataset:\n    def __init__(self, train_data, val_data):\n        self.train_examples = self.create_qa_example(train_data)\n        self.val_examples = self.create_qa_example(val_data)\n        self.train_dataset = Dataset.from_pandas(pd.DataFrame(self.train_examples))\n        self.val_dataset = Dataset.from_pandas(pd.DataFrame(self.val_examples))\n        self.dataset_dict = DatasetDict({\n            'train': self.train_dataset,\n            'validation': self.val_dataset\n        })\n\n    def create_qa_example(self, data):\n        examples = []\n        for row in data:\n            text = row['text']\n            question = row['label']\n            extracted_part = row.get('extracted_part', {})\n            if extracted_part and 'text' in extracted_part:\n                answer = extracted_part['text'][0].strip()\n                answer_start = extracted_part['answer_start'][0]\n                answer_end = extracted_part['answer_end'][0]\n            else:\n                answer = answer_start = answer_end = None\n\n            example = {'context': text, 'question': question, 'answer': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n            examples.append(example)\n        return examples\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_train_features(examples):\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=150,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n    tokenized_examples[\"start_positions\"] = []\n    tokenized_examples[\"end_positions\"] = []\n\n    for i, offsets in enumerate(offset_mapping):\n        input_ids = tokenized_examples[\"input_ids\"][i]\n        cls_index = input_ids.index(tokenizer.cls_token_id)\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        sample_index = sample_mapping[i]\n        answer_start = examples[\"answer_start\"][sample_index]\n        if answer_start == 0:\n            tokenized_examples[\"start_positions\"].append(cls_index)\n            tokenized_examples[\"end_positions\"].append(cls_index)\n        else:\n            start_char = answer_start\n            end_char = examples[\"answer_end\"][sample_index]\n            token_start_index = 0\n            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n                token_start_index += 1\n            token_end_index = len(input_ids) - 1\n            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n                token_end_index -= 1\n                \n            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n                tokenized_examples[\"start_positions\"].append(cls_index)\n                tokenized_examples[\"end_positions\"].append(cls_index)\n            else:\n                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n                    token_start_index += 1\n                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n                while offsets[token_end_index][1] >= end_char:\n                    token_end_index -= 1\n                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n\n    return tokenized_examples","metadata":{"execution":{"iopub.status.busy":"2023-04-18T00:07:24.951935Z","iopub.execute_input":"2023-04-18T00:07:24.953056Z","iopub.status.idle":"2023-04-18T00:07:24.968648Z","shell.execute_reply.started":"2023-04-18T00:07:24.953002Z","shell.execute_reply":"2023-04-18T00:07:24.967196Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model_name = \"valhalla/longformer-base-4096-finetuned-squadv1\"\nmax_length = 4000\npad_on_right = tokenizer.padding_side == \"right\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenized_dataset = qa_dataset.dataset_dict.map(prepare_train_features, batched=True, \n                                                 remove_columns=qa_dataset.dataset_dict[\"train\"].column_names)","metadata":{"execution":{"iopub.status.busy":"2023-04-18T00:09:30.655029Z","iopub.execute_input":"2023-04-18T00:09:30.655476Z","iopub.status.idle":"2023-04-18T00:09:37.659777Z","shell.execute_reply.started":"2023-04-18T00:09:30.655437Z","shell.execute_reply":"2023-04-18T00:09:37.658479Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30e6a819c3d0434d8d172e500706b2e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5d2fa783aec493a8cb3477848247562"}},"metadata":{}}]},{"cell_type":"code","source":"len(tokenized_dataset['train']['attention_mask'][6])","metadata":{"execution":{"iopub.status.busy":"2023-04-18T00:12:37.518780Z","iopub.execute_input":"2023-04-18T00:12:37.519268Z","iopub.status.idle":"2023-04-18T00:12:39.988906Z","shell.execute_reply.started":"2023-04-18T00:12:37.519223Z","shell.execute_reply":"2023-04-18T00:12:39.987904Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"4000"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-04-17T23:58:16.436158Z","iopub.execute_input":"2023-04-17T23:58:16.437404Z","iopub.status.idle":"2023-04-17T23:58:16.449019Z","shell.execute_reply.started":"2023-04-17T23:58:16.437351Z","shell.execute_reply":"2023-04-17T23:58:16.447352Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets['validation']","metadata":{"execution":{"iopub.status.busy":"2023-04-17T23:51:52.725869Z","iopub.execute_input":"2023-04-17T23:51:52.726307Z","iopub.status.idle":"2023-04-17T23:51:52.734017Z","shell.execute_reply.started":"2023-04-17T23:51:52.726271Z","shell.execute_reply":"2023-04-17T23:51:52.732796Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n    num_rows: 10570\n})"},"metadata":{}}]},{"cell_type":"code","source":"qa_dataset = QADataset(train_data, val_data)\nqa_dataset.dataset_dict","metadata":{"execution":{"iopub.status.busy":"2023-04-17T23:59:36.253717Z","iopub.execute_input":"2023-04-17T23:59:36.254183Z","iopub.status.idle":"2023-04-17T23:59:36.309295Z","shell.execute_reply.started":"2023-04-17T23:59:36.254134Z","shell.execute_reply":"2023-04-17T23:59:36.308161Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['context', 'question', 'answer', 'answer_start', 'answer_end'],\n        num_rows: 1439\n    })\n    validation: Dataset({\n        features: ['context', 'question', 'answer', 'answer_start', 'answer_end'],\n        num_rows: 360\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-04-17T23:56:04.286739Z","iopub.execute_input":"2023-04-17T23:56:04.287176Z","iopub.status.idle":"2023-04-17T23:56:04.295159Z","shell.execute_reply.started":"2023-04-17T23:56:04.287136Z","shell.execute_reply":"2023-04-17T23:56:04.293846Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"{'id': 711430708,\n 'text': 'УТВЕРЖДАЮ: Председатель закупочной комиссии, заместитель генерального директора - по логистике и МТО АО «АТХ» ____________________ Т.Ю. Шустова «01» сентября 2022 г. ДОКУМЕНТАЦИЯ О КОНКУРЕНТНОЙ ЗАКУПКЕ ЗАПРОС ПРЕДЛОЖЕНИЙ В ЭЛЕКТРОННОЙ ФОРМЕ, УЧАСТНИКАМИ КОТОРОГО МОГУТ БЫТЬ ТОЛЬКО СУБЪЕКТЫ МАЛОГО И СРЕДНЕГО ПРЕДПРИНИМАТЕЛЬСТВА на право заключения Договора на выполнение работ по ремонту зданий и сооружений г. Киров 2022 год. Стр.2 СОДЕРЖАНИЕ СОДЕРЖАНИЕ 2 I. ОБЩИЕ УСЛОВИЯ ПРОВЕДЕНИЯ закупки 3 1. ОБЩИЕ ПОЛОЖЕНИЯ 3 1.1. Правовой статус документов 3 1.2. Заказчик, предмет и условия проведения закупки. 3 1.3. Начальная (максимальная) цена договора 4 1.4. Требования к участникам закупки 4 1.5. Участие в закупке коллективных участников (группы лиц) 5 1.6. Привлечение соисполнителей (субподрядчиков) к исполнению договора 6 1.7. Расходы на участие в закупке и при заключении договора 7 1.8. Предоставление приоритетов товаров российского происхождения, работ, услуг, выполняемых, оказываемых российс 3.5.2, 5.6.4 Закупка по единичным расценкам Нет.',\n 'label': 'обеспечение гарантийных обязательств',\n 'extracted_part': {'text': [''], 'answer_start': [0], 'answer_end': [0]}}"},"metadata":{}}]},{"cell_type":"code","source":"!pip list | grep transformers","metadata":{"execution":{"iopub.status.busy":"2023-04-12T23:16:51.641589Z","iopub.execute_input":"2023-04-12T23:16:51.642340Z","iopub.status.idle":"2023-04-12T23:16:54.350510Z","shell.execute_reply.started":"2023-04-12T23:16:51.642293Z","shell.execute_reply":"2023-04-12T23:16:54.349209Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"transformers                           4.27.4\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T23:25:15.486969Z","iopub.execute_input":"2023-04-17T23:25:15.487352Z","iopub.status.idle":"2023-04-17T23:25:15.520874Z","shell.execute_reply.started":"2023-04-17T23:25:15.487316Z","shell.execute_reply":"2023-04-17T23:25:15.519604Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f50577ab98714927b2476f464fb70926"}},"metadata":{}}]},{"cell_type":"code","source":"from IPython.display import display, HTML\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport json\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW, get_linear_schedule_with_warmup, LongformerTokenizerFast\nfrom transformers import BertTokenizer, BertForQuestionAnswering, TFAutoModelForQuestionAnswering, TFLongformerForQuestionAnswering\nfrom transformers import BigBirdTokenizer, BigBirdForQuestionAnswering, BigBirdPegasusForQuestionAnswering, PegasusTokenizer, PegasusTokenizerFast\nimport torch\nimport time\nimport nltk\nfrom torch.nn.utils.rnn import pad_sequence\nimport math\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW\nimport json\n\nimport tensorflow as tf\nimport re\nfrom torch.nn.utils.rnn import pad_sequence\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tokenizers import BertWordPieceTokenizer\nfrom transformers import LongformerConfig","metadata":{"execution":{"iopub.status.busy":"2023-04-17T23:25:49.118371Z","iopub.execute_input":"2023-04-17T23:25:49.119193Z","iopub.status.idle":"2023-04-17T23:25:49.128322Z","shell.execute_reply.started":"2023-04-17T23:25:49.119138Z","shell.execute_reply":"2023-04-17T23:25:49.127284Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, LongformerConfig\nfrom transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\nfrom transformers import default_data_collator\n\n\nclass QATrainer:\n    def __init__(self, model_name, train_dataset, val_dataset, batch_size=16, epochs=3):\n        self.model_name = model_name\n        self.config = LongformerConfig()\n#         self.model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n        self.model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n#         self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.train_dataset = train_dataset\n        self.val_dataset = val_dataset\n        self.batch_size = batch_size\n        self.epochs = epochs\n    \n    def training(self):\n        model_name = self.model_name.split(\"/\")[-1]\n        args = TrainingArguments(\n            model_name,\n            evaluation_strategy = \"epoch\",\n            learning_rate=2e-5,\n            per_device_train_batch_size=self.batch_size,\n            per_device_eval_batch_size=self.batch_size,\n            num_train_epochs=self.epochs,\n            weight_decay=0.01,\n            push_to_hub=True,\n        )\n\n        data_collator = default_data_collator\n        trainer = Trainer(\n            self.model,\n            args,\n            train_dataset=self.train_dataset,\n            eval_dataset=self.val_dataset,\n            data_collator=data_collator,\n            tokenizer=self.tokenizer,\n        )\n        \n        trainer.train()\n        trainer.save_model(\"QA-trained\")\n        \n        return self.model\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T23:24:44.220447Z","iopub.execute_input":"2023-04-17T23:24:44.220875Z","iopub.status.idle":"2023-04-17T23:24:56.208489Z","shell.execute_reply.started":"2023-04-17T23:24:44.220838Z","shell.execute_reply":"2023-04-17T23:24:56.207066Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# загружаем данные для обучения\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/train.json', 'r', encoding='utf-8') as file:\n    train_data = json.load(file)\n\n# загружаем данные для предсказания\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/test.json', 'r', encoding='utf-8') as file:\n    test_data = json.load(file)\n\n# Разбиваем данные на обучающую и валидационную выборки\ntrain_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T23:46:47.555958Z","iopub.execute_input":"2023-04-17T23:46:47.557964Z","iopub.status.idle":"2023-04-17T23:46:47.784424Z","shell.execute_reply.started":"2023-04-17T23:46:47.557896Z","shell.execute_reply":"2023-04-17T23:46:47.783360Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndef create_dataframe(data, fields, subfields):\n    main_df = pd.DataFrame(data)[fields]\n    sub_df_list = []\n    for subfield in subfields:\n        sub_df = pd.DataFrame(list(main_df[subfield]))\n        sub_df.columns = [f\"{subfield}_{col}\" for col in sub_df.columns]\n        sub_df_list.append(sub_df)\n    main_df = main_df.drop(columns=['extracted_part'])\n    return pd.concat([main_df] + sub_df_list, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T13:12:52.273119Z","iopub.execute_input":"2023-04-17T13:12:52.274505Z","iopub.status.idle":"2023-04-17T13:12:52.285400Z","shell.execute_reply.started":"2023-04-17T13:12:52.274441Z","shell.execute_reply":"2023-04-17T13:12:52.284098Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"train_df = create_dataframe(train_data, ['text', 'label', \"extracted_part\"], ['extracted_part'])\ndisplay(HTML(train_df[:2].to_html()))","metadata":{"execution":{"iopub.status.busy":"2023-04-15T05:27:48.818263Z","iopub.execute_input":"2023-04-15T05:27:48.818699Z","iopub.status.idle":"2023-04-15T05:27:48.846448Z","shell.execute_reply.started":"2023-04-15T05:27:48.818660Z","shell.execute_reply":"2023-04-15T05:27:48.845321Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>extracted_part_text</th>\n      <th>extracted_part_answer_start</th>\n      <th>extracted_part_answer_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>УТВЕРЖДАЮ: Председатель закупочной комиссии, заместитель генерального директора - по логистике и МТО АО «АТХ» ____________________ Т.Ю. Шустова «01» сентября 2022 г. ДОКУМЕНТАЦИЯ О КОНКУРЕНТНОЙ ЗАКУПКЕ ЗАПРОС ПРЕДЛОЖЕНИЙ В ЭЛЕКТРОННОЙ ФОРМЕ, УЧАСТНИКАМИ КОТОРОГО МОГУТ БЫТЬ ТОЛЬКО СУБЪЕКТЫ МАЛОГО И СРЕДНЕГО ПРЕДПРИНИМАТЕЛЬСТВА на право заключения Договора на выполнение работ по ремонту зданий и сооружений г. Киров 2022 год. Стр.2 СОДЕРЖАНИЕ СОДЕРЖАНИЕ 2 I. ОБЩИЕ УСЛОВИЯ ПРОВЕДЕНИЯ закупки 3 1. ОБЩИЕ ПОЛОЖЕНИЯ 3 1.1. Правовой статус документов 3 1.2. Заказчик, предмет и условия проведения закупки. 3 1.3. Начальная (максимальная) цена договора 4 1.4. Требования к участникам закупки 4 1.5. Участие в закупке коллективных участников (группы лиц) 5 1.6. Привлечение соисполнителей (субподрядчиков) к исполнению договора 6 1.7. Расходы на участие в закупке и при заключении договора 7 1.8. Предоставление приоритетов товаров российского происхождения, работ, услуг, выполняемых, оказываемых российс 3.5.2, 5.6.4 Закупка по единичным расценкам Нет.</td>\n      <td>обеспечение гарантийных обязательств</td>\n      <td>[]</td>\n      <td>[0]</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>УТВЕРЖДАЮ Начальник государственного бюджетного учреждения Волгоградской области «Волгоградская городская станция по борьбе с болезнями животных» __________________ В.Н. Рудников \" \" 2022 г. М.П. ИЗВЕЩЕНИЕ О ПРОВЕДЕНИИ ЗАПРОСА КОТИРОВОК В ЭЛЕКТРОННОЙ УТВЕРЖДАЮ Начальник государственного бюджетного учреждения Волгоградской области «Волгоградская городская станция по борьбе с болезнями животных» __________________ В.Н. Рудников \" \" 2022 г. М.П. ИЗВЕЩЕНИЕ О ПРОВЕДЕНИИ ЗАПРОСА КОТИРОВОК В ЭЛЕКТРОННОЙ ФОРМЕ, УЧАСТНИКАМИ КОТОРОГО МОГУТ БЫТЬ ТОЛЬКО СУБЪЕКТЫ МАЛОГО И СРЕДНЕГО ПРЕДПРИНИМАТЕЛЬСТВА на поставку расходных материалов № п/п Наименование Сведения 1 Используемый способ закупки Запрос котировок в электронной форме (далее – запрос котировок) 2 Информация о Заказчике (контактная информация) Наименование: Государственное бюджетное учреждение Волгоградской области «Волгоградская городская станция по борьбе с болезнями животных» (ГБУ ВО «Волгоградская горСББЖ») Почтовый адрес: 400107, Волгоградская обл., г. Волгоград, ул. Карла Либкнехта, 6 Адрес электронной почты: zakupki-vet@mail.ru Номер контактного телефона: +7 9610675527 Ответственное должностное лицо Заказчика: Шкитина Ольга Николаевна 3 Адрес электронной площадки в сети Интернет w 22</td>\n      <td>обеспечение гарантийных обязательств</td>\n      <td>[]</td>\n      <td>[0]</td>\n      <td>[0]</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"def create_qa_examples(data):\n    examples = []\n    for row in data:\n        text = row['text']\n        question = row['label']\n        extracted_part = row.get('extracted_part', {})\n        if extracted_part and 'text' in extracted_part:\n            answer = extracted_part['text'][0].strip()\n            answer_start = extracted_part['answer_start'][0]\n            answer_end = extracted_part['answer_end'][0]\n        else:\n            answer = answer_start = answer_end = None\n\n        example = {'context': text, 'question': question, 'answer': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n        examples.append(example)\n    return examples","metadata":{"execution":{"iopub.status.busy":"2023-04-15T05:37:48.633798Z","iopub.execute_input":"2023-04-15T05:37:48.634538Z","iopub.status.idle":"2023-04-15T05:37:48.643183Z","shell.execute_reply.started":"2023-04-15T05:37:48.634495Z","shell.execute_reply":"2023-04-15T05:37:48.641772Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"create_qa_examples(train_data)[0]['context']","metadata":{"execution":{"iopub.status.busy":"2023-04-15T05:38:26.609103Z","iopub.execute_input":"2023-04-15T05:38:26.609554Z","iopub.status.idle":"2023-04-15T05:38:26.621199Z","shell.execute_reply.started":"2023-04-15T05:38:26.609512Z","shell.execute_reply":"2023-04-15T05:38:26.619914Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'УТВЕРЖДАЮ: Председатель закупочной комиссии, заместитель генерального директора - по логистике и МТО АО «АТХ» ____________________ Т.Ю. Шустова «01» сентября 2022 г. ДОКУМЕНТАЦИЯ О КОНКУРЕНТНОЙ ЗАКУПКЕ ЗАПРОС ПРЕДЛОЖЕНИЙ В ЭЛЕКТРОННОЙ ФОРМЕ, УЧАСТНИКАМИ КОТОРОГО МОГУТ БЫТЬ ТОЛЬКО СУБЪЕКТЫ МАЛОГО И СРЕДНЕГО ПРЕДПРИНИМАТЕЛЬСТВА на право заключения Договора на выполнение работ по ремонту зданий и сооружений г. Киров 2022 год. Стр.2 СОДЕРЖАНИЕ СОДЕРЖАНИЕ 2 I. ОБЩИЕ УСЛОВИЯ ПРОВЕДЕНИЯ закупки 3 1. ОБЩИЕ ПОЛОЖЕНИЯ 3 1.1. Правовой статус документов 3 1.2. Заказчик, предмет и условия проведения закупки. 3 1.3. Начальная (максимальная) цена договора 4 1.4. Требования к участникам закупки 4 1.5. Участие в закупке коллективных участников (группы лиц) 5 1.6. Привлечение соисполнителей (субподрядчиков) к исполнению договора 6 1.7. Расходы на участие в закупке и при заключении договора 7 1.8. Предоставление приоритетов товаров российского происхождения, работ, услуг, выполняемых, оказываемых российс 3.5.2, 5.6.4 Закупка по единичным расценкам Нет.'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, RobertaTokenizer, LongformerTokenizer, LongformerForQuestionAnswering, LongformerTokenizer\nimport transformers\nmax_seq_length = 4000\nmodel_name = \"valhalla/longformer-base-4096-finetuned-squadv1\"\n# LongformerTokenizer.from_pretrained(\"valhalla/longformer-base-4096-finetuned-squadv1\")\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nconfig = LongformerConfig.from_pretrained('valhalla/longformer-base-4096-finetuned-squadv1')\nconfig.attention_mode = 'sliding_chunks'\n\nnum_epochs = 3\nbatch_size = 16\npad_on_right = tokenizer.padding_side == \"right\"\ntrain_dataset = QADataset(train_data, model_name, max_seq_length)\nval_dataset = QADataset(val_data, model_name, max_seq_length)\n# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n# val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\nassert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T13:46:25.996336Z","iopub.execute_input":"2023-04-17T13:46:25.997755Z","iopub.status.idle":"2023-04-17T13:46:31.551920Z","shell.execute_reply.started":"2023-04-17T13:46:25.997701Z","shell.execute_reply":"2023-04-17T13:46:31.550408Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-04-17T13:46:33.259965Z","iopub.execute_input":"2023-04-17T13:46:33.260859Z","iopub.status.idle":"2023-04-17T13:46:33.284040Z","shell.execute_reply.started":"2023-04-17T13:46:33.260810Z","shell.execute_reply":"2023-04-17T13:46:33.282538Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[    0, 41613, 15389,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]]), 'start_positions': [0], 'end_positions': [0]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer('<s>', '<s>')","metadata":{"execution":{"iopub.status.busy":"2023-04-17T13:20:36.224458Z","iopub.execute_input":"2023-04-17T13:20:36.225345Z","iopub.status.idle":"2023-04-17T13:20:36.237258Z","shell.execute_reply.started":"2023-04-17T13:20:36.225276Z","shell.execute_reply":"2023-04-17T13:20:36.235190Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [0, 0, 2, 2, 0, 2], 'attention_mask': [1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"QAtrainer = QATrainer(\n    model_name=model_name,\n    train_dataset=tokenized_dataset['train'],\n    val_dataset=tokenized_dataset['validation']\n)\n\nQAtrainer.training()","metadata":{"execution":{"iopub.status.busy":"2023-04-18T00:14:02.911723Z","iopub.execute_input":"2023-04-18T00:14:02.912499Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/595M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ef1b770a56f476395143a1ff55b0fd9"}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"Cloning https://huggingface.co/karnaksp/longformer-base-4096-finetuned-squadv1 into local empty directory.\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230418_001654-o0hlj8sg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/irinyakov2016/huggingface/runs/o0hlj8sg' target=\"_blank\">usual-sun-4</a></strong> to <a href='https://wandb.ai/irinyakov2016/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/irinyakov2016/huggingface' target=\"_blank\">https://wandb.ai/irinyakov2016/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/irinyakov2016/huggingface/runs/o0hlj8sg' target=\"_blank\">https://wandb.ai/irinyakov2016/huggingface/runs/o0hlj8sg</a>"},"metadata":{}}]},{"cell_type":"code","source":"\n\nfrom transformers import BertConfig, BertModel\n\n# bert_config = BertConfig(\n#     vocab_size=32000,\n#     hidden_size=768,\n#     num_hidden_layers=12,\n#     num_attention_heads=12,\n#     intermediate_size=3072,\n#     hidden_dropout_prob=0.1,\n#     attention_probs_dropout_prob=0.1,\n#     max_position_embeddings=512,\n#     type_vocab_size=2,\n#     initializer_range=0.02,\n#     layer_norm_eps=1e-12,\n#     gradient_checkpointing=False,\n#     position_embedding_type=\"absolute\",\n#     use_cache=True,\n#     is_decoder=False,\n#     pad_token_id=0,\n#     bos_token_id=1,\n#     eos_token_id=2\n# )\n\ntokenizer = AutoTokenizer.from_pretrained(\"valhalla/longformer-base-4096-finetuned-squadv1\")\nmax_seq_length = 4000\nbatch_size = 16\nepochs = eps = 1\n     \ntrain_dataset = QADataset(train_data, tokenizer, max_seq_length)\nval_dataset = QADataset(val_data, tokenizer, max_seq_length)\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n\n# qa_model = QAModel(bert_config)\n# qa_trainer = QATrainer(qa_model, train_dataloader, val_dataloader, lr=1e-12, eps=eps)\n# train_losses, val_losses = qa_trainer.train(epochs)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-13T11:39:56.008829Z","iopub.execute_input":"2023-04-13T11:39:56.009856Z","iopub.status.idle":"2023-04-13T11:39:56.335014Z","shell.execute_reply.started":"2023-04-13T11:39:56.009804Z","shell.execute_reply":"2023-04-13T11:39:56.333795Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, val_loader):\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for step, batch in enumerate(val_loader):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            segment_ids = batch['segment_ids'].to(device)\n            start_positions = batch['start_positions'].to(device)\n            end_positions = batch['end_positions'].to(device)\n            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=segment_ids, start_positions=start_positions, end_positions=end_positions)\n            loss = outputs.loss\n            total_loss += loss.item()\n        avg_loss = total_loss / len(val_loader)\n        return avg_loss\n\ndef predict(model, test_loader):\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for step, batch in enumerate(test_loader):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            segment_ids = batch['segment_ids'].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=segment_ids)\n            start_logits, end_logits = outputs.start_logits, outputs.end_logits\n            start_preds = torch.softmax(start_logits, dim=1).cpu().detach().numpy()\n            end_preds = torch.softmax(end_logits, dim=1).cpu().detach().numpy()\n            for i in range(len(start_preds)):\n                start_pred = np.argmax(start_preds[i])\n                end_pred = np.argmax(end_preds[i])\n                if start_pred > end_pred:\n                    answer = \"\"\n                else:\n                    answer = tokenizer.decode(input_ids[i][start_pred:end_pred+1], skip_special_tokens=True)\n                predictions.append({\n                    \"context\": batch['context'][i],\n                    \"question\": batch['question'][i],\n                    \"extracted_part\": answer\n                })\n    with open('predictions.json', 'w', encoding='utf-8') as f:\n        json.dump(predictions, f, ensure_ascii=False, indent=4)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-12T08:19:22.249349Z","iopub.status.idle":"2023-04-12T08:19:22.250299Z","shell.execute_reply.started":"2023-04-12T08:19:22.249973Z","shell.execute_reply":"2023-04-12T08:19:22.250010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class QADataset(Dataset):\n    def __init__(self, data, tokenizer, max_seq_length):\n        self.examples = self.create_qa_examples(data)\n        self.tokenizer = tokenizer\n        self.max_seq_length = max_seq_length\n        self.skip = False\n\n    def __len__(self):\n        return len(self.examples)\n    \n    def __getitem__(self, idx):\n        example = self.examples[idx]\n        context = example['context']\n        question = example['question']\n        answer = example['answer']\n        answer_start = example['answer_start']\n        answer_end = example['answer_end']\n        assert answer_end <= len(example['context'])\n        is_char_in_ans = [0] * len(context)\n        for i in range(answer_start, answer_end):\n            is_char_in_ans[i] = 1\n        tokenized_context = self.tokenizer.encode_plus(context, add_special_tokens=False, return_offsets_mapping=True, return_tensors=\"tf\")\n        ans_token_idx = []\n        is_ans_token = [0] * len(tokenized_context)\n\n        for idx, token in enumerate(tokenized_context):\n            token_start = tokenized_context.token_to_chars(idx)[0]\n            token_end = tokenized_context.token_to_chars(idx)[1]\n            if sum(is_char_in_ans[token_start:token_end]) > 0:\n                ans_token_idx.append(idx)\n                for i in range(token_start, token_end):\n                    is_ans_token[i] = 1\n        if sum(is_ans_token) == 0:\n            start_token_idx, end_token_idx = 0, 0\n        else:\n            start_token_idx = ans_token_idx[0]\n            end_token_idx = ans_token_idx[-1]\n            while start_token_idx > 0 and is_ans_token[tokenized_context.token_to_chars(start_token_idx-1)[0]]:\n                start_token_idx -= 1\n            while end_token_idx < len(tokenized_context)-1 and is_ans_token[tokenized_context.token_to_chars(end_token_idx+1)[1]-1]:\n                end_token_idx += 1\n            \n\n        tokenized_question = self.tokenizer.encode_plus(question, return_offsets_mapping=True, return_tensors=\"tf\")\n        tokens = ['<s>'] + tokenized_context.tokens() + ['</s>']+ ['</s>'] + tokenized_question.tokens() + ['</s>']\n        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n        token_type_ids = [0] * (len(tokenized_context.tokens())+2) + [1] * (len(\n            tokenized_question.tokens())+2)\n        attention_mask = [1] * len(input_ids)\n        padding_length = self.max_seq_length - len(input_ids)\n        if padding_length > 0:  # pad\n            input_ids = input_ids + ([0] * padding_length)\n            attention_mask = attention_mask + ([0] * padding_length)\n            token_type_ids = token_type_ids + ([0] * padding_length)\n        elif padding_length < 0:  # skip\n            self.skip = True\n            return\n        features = []\n#         encoded_dict = self.tokenizer.encode_plus(\n#             question,\n#             context,\n#             add_special_tokens=True,\n#             truncation='longest_first',\n#             max_length=self.max_seq_length,\n#             return_tensors='pt'\n#         )\n#         input_ids = encoded_dict['input_ids'].squeeze()\n#         attention_mask = encoded_dict['attention_mask'].squeeze()\n#         input_ids = torch.nn.functional.pad(encoded_dict['input_ids'], (0, self.max_seq_length - encoded_dict['input_ids'].shape[1]), mode='constant', value=0)\n#         attention_mask = torch.nn.functional.pad(encoded_dict['attention_mask'], (0, self.max_seq_length - encoded_dict['attention_mask'].shape[1]), mode='constant', value=0)\n        \n        features = {'input_ids': input_ids, 'attention_mask': attention_mask, \n                    'token_type_ids': token_type_ids, 'start_token_idx': start_token_idx, 'end_token_idx': end_token_idx}\n#         max_len_dict = {}\n#         for key, value in features.items():\n#             if isinstance(value, (list, tuple)):\n#                 max_len_dict[key] = max(len(seq) for seq in value)\n#         for key, value in features.items():\n#             if isinstance(value, (list, tuple)):\n#                 max_len = max_len_dict[key]\n#                 for i in range(len(value)):\n#                     pad_len = max_len - len(value[i])\n#                     value[i] = torch.cat([value[i], torch.zeros(pad_len, dtype=torch.long)])\n#                 features[key] = torch.stack(value)\n\n        return features\n    \n    def create_qa_examples(self, data):\n        examples = []\n        for row in data:\n            text = row['text']\n            question = row['label']\n            extracted_part = row.get('extracted_part', {})\n            if extracted_part and 'text' in extracted_part:\n                answer = extracted_part['text'][0].strip()\n                answer_start = extracted_part['answer_start'][0]\n                answer_end = extracted_part['answer_end'][0]\n            else:\n                answer = answer_start = answer_end = None\n\n            example = {'context': text, 'question': question, 'answer': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n            examples.append(example)\n        return examples\n    \n    \n    @staticmethod\n    def prepare_test_data(data):\n        examples = []\n        for row in data:\n            text = row['text']\n            question = row['label']\n            example = {'context': text, 'question': question}\n            examples.append(example)\n        return examples\n\ndef collate_fn(batch, device):\n    input_ids = pad_sequence([torch.tensor(example['input_ids']) for example in batch], batch_first=True, padding_value=0).to(device)\n    attention_mask = pad_sequence([torch.tensor(example['attention_mask']) for example in batch], batch_first=True, padding_value=0).to(device)\n    token_type_ids = pad_sequence([torch.tensor(example['token_type_ids']) for example in batch], batch_first=True, padding_value=0).to(device)\n    start_positions = torch.tensor([example['answer_start'] for example in batch]).to(device)\n    end_positions = torch.tensor([example['answer_end'] for example in batch]).to(device)\n    return {\n        'input_ids': input_ids,\n        'attention_mask': attention_mask,\n        'token_type_ids': token_type_ids,\n        'start_positions': start_positions,\n        'end_positions': end_positions\n    }\n\n\ndef create_inputs_targets(dataset):\n    dataset_dict = {\n        \"input_ids\": [],\n        \"token_type_ids\": [],\n        \"attention_mask\": [],\n        \"start_token_idx\": [],\n        \"end_token_idx\": [],\n    }\n    for idx in range(len(dataset)):\n        example = dataset[idx]\n        for key in dataset_dict:\n            if isinstance(example[key], torch.Tensor):\n                value = example[key].numpy().tolist()\n            else:\n                value = example[key]\n            dataset_dict[key].append(value)\n\n\n    x = [\n        dataset_dict[\"input_ids\"],\n        dataset_dict[\"token_type_ids\"],\n        dataset_dict[\"attention_mask\"],\n    ]\n    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n    return x, y\n\ndef x_y_split(model_name, train_data, validation_data, batch_size):\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = TFAutoModelForQuestionAnswering.from_pretrained(model_name)\n#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    train_dataset = QADataset(train_data, tokenizer, max_seq_length)\n#     train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True,\n#                                    collate_fn=lambda batch: collate_fn(batch, device))\n    x_train, y_train = create_inputs_targets(train_dataset)\n    \n    validation_dataset = QADataset(validation_data, tokenizer, max_seq_length)\n#     validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, drop_last=True,\n#                                         collate_fn=lambda batch: collate_fn(batch, device))\n    x_val, y_val = create_inputs_targets(validation_dataset)\n\n    return x_train, y_train, x_val, y_val\n\n\n\ndef create_model(model_name):\n    ## BERT encoder\n    encoder = TFLongformerForQuestionAnswering.from_pretrained(model_name)\n\n    ## QA Model\n    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n    embedding = encoder(\n        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n    )[0]\n\n    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n    start_logits = layers.Flatten()(start_logits)\n\n    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n    end_logits = layers.Flatten()(end_logits)\n\n    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n\n    model = keras.Model(\n        inputs=[input_ids, token_type_ids, attention_mask],\n        outputs=[start_probs, end_probs],\n    )\n    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n    optimizer = keras.optimizers.Adam(lr=5e-5)\n    model.compile(optimizer=optimizer, loss=[loss, loss])\n    return model\n\nclass ExactMatch(keras.callbacks.Callback):\n    def __init__(self, x_eval, y_eval):\n        super().__init__()\n        self.x_eval = x_eval\n        self.y_eval = y_eval\n\n    def on_epoch_end(self, epoch, logs=None):\n        pred_start, pred_end = self.model.predict(self.x_eval)\n        count = 0\n        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n            offsets = squad_eg.context_token_to_char\n            start = np.argmax(start)\n            end = np.argmax(end)\n            if start >= len(offsets):\n                continue\n            pred_char_start = offsets[start][0]\n            if end < len(offsets):\n                pred_char_end = offsets[end][1]\n                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n            else:\n                pred_ans = squad_eg.context[pred_char_start:]\n\n            if pred_ans in squad_eg.all_answers:\n                count += 1\n        acc = count / len(self.y_eval[0])\n        print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-13T11:58:50.337437Z","iopub.execute_input":"2023-04-13T11:58:50.338616Z","iopub.status.idle":"2023-04-13T11:58:50.383782Z","shell.execute_reply.started":"2023-04-13T11:58:50.338558Z","shell.execute_reply":"2023-04-13T11:58:50.382176Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"valhalla/longformer-base-4096-finetuned-squadv1\")\nexamp = QADataset(train_data, tokenizer, max_seq_length)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T05:05:04.559433Z","iopub.execute_input":"2023-04-13T05:05:04.560576Z","iopub.status.idle":"2023-04-13T05:05:04.974003Z","shell.execute_reply.started":"2023-04-13T05:05:04.560529Z","shell.execute_reply":"2023-04-13T05:05:04.972592Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"QADataset(train_data, tokenizer, max_seq_length)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T05:08:03.732754Z","iopub.execute_input":"2023-04-13T05:08:03.733471Z","iopub.status.idle":"2023-04-13T05:08:03.745876Z","shell.execute_reply.started":"2023-04-13T05:08:03.733426Z","shell.execute_reply":"2023-04-13T05:08:03.744636Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"<__main__.QADataset at 0x707ab47127d0>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# загружаем данные для обучения\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/train.json', 'r', encoding='utf-8') as file:\n    train_data = json.load(file)\n\n# загружаем данные для предсказания\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/test.json', 'r', encoding='utf-8') as file:\n    test_data = json.load(file)\n\n# Разбиваем данные на обучающую и валидационную выборки\ntrain_data, validation_data = train_test_split(train_data[:50], test_size=0.2, random_state=42)\nmax_seq_length = 4000\nmodel_name = \"valhalla/longformer-base-4096-finetuned-squadv1\"\nconfiguration = LongformerConfig()\nnum_epochs = 3\n\nx_train, y_train, x_val, y_val = x_y_split(model_name = model_name, train_data = train_data, validation_data = validation_data, batch_size = 16)\nmax_len = len(x_train[0][0])","metadata":{"execution":{"iopub.status.busy":"2023-04-13T11:59:42.370540Z","iopub.execute_input":"2023-04-13T11:59:42.370958Z","iopub.status.idle":"2023-04-13T12:00:09.355304Z","shell.execute_reply.started":"2023-04-13T11:59:42.370921Z","shell.execute_reply":"2023-04-13T12:00:09.353799Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tf_model.h5:   0%|          | 0.00/595M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"505eb86c2d5142cd9b43075f58fbbe29"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFLongformerForQuestionAnswering.\n\nAll the layers of TFLongformerForQuestionAnswering were initialized from the model checkpoint at valhalla/longformer-base-4096-finetuned-squadv1.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerForQuestionAnswering for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"len(y_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-04-13T12:06:20.562455Z","iopub.execute_input":"2023-04-13T12:06:20.562884Z","iopub.status.idle":"2023-04-13T12:06:20.571588Z","shell.execute_reply.started":"2023-04-13T12:06:20.562844Z","shell.execute_reply":"2023-04-13T12:06:20.569884Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"40"},"metadata":{}}]},{"cell_type":"code","source":"x_train имеет структуру словаря, в котором есть 3 подсловаря - признака, в каждом из них набор примеров n-го количества, в каждом примере уже непосредственно находятся данные\nв y_train 2 словаря, которые содержат n примеров, в каждом из которых находится таргет. \nкакие модели обучения можно написать на таких данных, не пользуясь предобученными моделями и их ограничениями","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntf.debugging.set_log_device_placement(True)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T02:22:05.743042Z","iopub.execute_input":"2023-04-13T02:22:05.744206Z","iopub.status.idle":"2023-04-13T02:22:05.750685Z","shell.execute_reply.started":"2023-04-13T02:22:05.744131Z","shell.execute_reply":"2023-04-13T02:22:05.749227Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))","metadata":{"execution":{"iopub.status.busy":"2023-04-13T02:26:21.023641Z","iopub.execute_input":"2023-04-13T02:26:21.024036Z","iopub.status.idle":"2023-04-13T02:26:21.039223Z","shell.execute_reply.started":"2023-04-13T02:26:21.024002Z","shell.execute_reply":"2023-04-13T02:26:21.037882Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Device mapping:\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.client.session.Session at 0x79cc6d6283d0>"},"metadata":{}}]},{"cell_type":"code","source":"use_tpu = False  # Change to True if using TPU\n\nif use_tpu:\n    # Create distribution strategy\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    strategy = tf.distribute.TPUStrategy(tpu)\n\n    # Create model\n    with strategy.scope():\n        print('TPU used')\n        model = create_model(model_name)\nelse:\n#     # Use GPU if TPU is not available\n#     if tf.config.list_physical_devices('GPU'):\n#         strategy = tf.distribute.MirroredStrategy()\n        \n#     else:\n    strategy = tf.distribute.OneDeviceStrategy(device=\"/CPU:0\")\n\n    with strategy.scope():\n        model = create_model(model_name)\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:46:42.712019Z","iopub.execute_input":"2023-04-13T09:46:42.712445Z","iopub.status.idle":"2023-04-13T09:47:34.658095Z","shell.execute_reply.started":"2023-04-13T09:46:42.712410Z","shell.execute_reply":"2023-04-13T09:47:34.656781Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFLongformerForQuestionAnswering.\n\nAll the layers of TFLongformerForQuestionAnswering were initialized from the model checkpoint at valhalla/longformer-base-4096-finetuned-squadv1.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerForQuestionAnswering for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x764ef2d33de0>> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","output_type":"stream"},{"name":"stderr","text":"There should be exactly three separator tokens: 2 in every sample for questions answering. You might also consider to set `global_attention_mask` manually in the forward function to avoid this. This is most likely an error. The global attention is disabled for this forward pass.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 4000)]       0           []                               \n                                                                                                  \n input_3 (InputLayer)           [(None, 4000)]       0           []                               \n                                                                                                  \n input_2 (InputLayer)           [(None, 4000)]       0           []                               \n                                                                                                  \n tf_longformer_for_question_ans  TFLongformerQuestio  148070402  ['input_1[0][0]',                \n wering_1 (TFLongformerForQuest  nAnsweringModelOutp              'input_3[0][0]',                \n ionAnswering)                  ut(loss=None, start               'input_2[0][0]']                \n                                _logits=(None, 4000                                               \n                                ),                                                                \n                                 end_logits=(None,                                                \n                                4000),                                                            \n                                 hidden_states=None                                               \n                                , attentions=None,                                                \n                                global_attentions=N                                               \n                                one)                                                              \n                                                                                                  \n start_logit (Dense)            (None, 1)            4000        ['tf_longformer_for_question_answ\n                                                                 ering_1[0][1]']                  \n                                                                                                  \n end_logit (Dense)              (None, 1)            4000        ['tf_longformer_for_question_answ\n                                                                 ering_1[0][1]']                  \n                                                                                                  \n flatten (Flatten)              (None, 1)            0           ['start_logit[0][0]']            \n                                                                                                  \n flatten_1 (Flatten)            (None, 1)            0           ['end_logit[0][0]']              \n                                                                                                  \n activation (Activation)        (None, 1)            0           ['flatten[0][0]']                \n                                                                                                  \n activation_1 (Activation)      (None, 1)            0           ['flatten_1[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 148,078,402\nTrainable params: 148,078,402\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\nprint(tf.test.is_built_with_cuda())\nprint(tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-13T08:30:54.952204Z","iopub.execute_input":"2023-04-13T08:30:54.952882Z","iopub.status.idle":"2023-04-13T08:30:54.962612Z","shell.execute_reply.started":"2023-04-13T08:30:54.952843Z","shell.execute_reply":"2023-04-13T08:30:54.960473Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"2.11.0\nTrue\nTrue\n","output_type":"stream"}]},{"cell_type":"code","source":"\nx_train_np = [np.array(x_train[0]), np.array(x_train[1]), np.array(x_train[2])]\ny_train_np = [np.array(y_train[0]), np.array(y_train[1])]\nx_val_np = [np.array(x_val[0]), np.array(x_val[1]), np.array(x_val[2])]\ny_val_np = [np.array(y_val[0]), np.array(y_val[1])]\nexact_match_callback = ExactMatch(x_val_np, y_val_np)\nmodel.fit(\n    x_train_np,\n    y_train_np,\n    validation_data=(x_val_np, y_val_np),\n    epochs=1,\n    verbose=2,\n    batch_size=64,\n#     callbacks=[exact_match_callback],\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:47:50.637213Z","iopub.execute_input":"2023-04-13T09:47:50.637644Z","iopub.status.idle":"2023-04-13T09:50:17.440222Z","shell.execute_reply.started":"2023-04-13T09:47:50.637606Z","shell.execute_reply":"2023-04-13T09:50:17.438084Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"There should be exactly three separator tokens: 2 in every sample for questions answering. You might also consider to set `global_attention_mask` manually in the forward function to avoid this. This is most likely an error. The global attention is disabled for this forward pass.\nThere should be exactly three separator tokens: 2 in every sample for questions answering. You might also consider to set `global_attention_mask` manually in the forward function to avoid this. This is most likely an error. The global attention is disabled for this forward pass.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1655000812.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#     callbacks=[exact_match_callback],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model/tf_longformer_for_question_answering_1/longformer/embeddings/Gather_2' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_27/1655000812.py\", line 12, in <module>\n      batch_size=64,\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\", line 2224, in run_call_with_unpacked_inputs\n      version=1,\n    File \"/opt/conda/lib/python3.7/site-packages/transformers/models/longformer/modeling_tf_longformer.py\", line 2275, in call\n      outputs = self.longformer(\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\", line 2224, in run_call_with_unpacked_inputs\n      version=1,\n    File \"/opt/conda/lib/python3.7/site-packages/transformers/models/longformer/modeling_tf_longformer.py\", line 1764, in call\n      embedding_output = self.embeddings(\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/transformers/models/longformer/modeling_tf_longformer.py\", line 571, in call\n      token_type_embeds = tf.gather(params=self.token_type_embeddings, indices=token_type_ids)\nNode: 'model/tf_longformer_for_question_answering_1/longformer/embeddings/Gather_2'\nindices[37,2809] = 1 is not in [0, 1)\n\t [[{{node model/tf_longformer_for_question_answering_1/longformer/embeddings/Gather_2}}]] [Op:__inference_train_function_195674]"],"ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node 'model/tf_longformer_for_question_answering_1/longformer/embeddings/Gather_2' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_27/1655000812.py\", line 12, in <module>\n      batch_size=64,\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\", line 2224, in run_call_with_unpacked_inputs\n      version=1,\n    File \"/opt/conda/lib/python3.7/site-packages/transformers/models/longformer/modeling_tf_longformer.py\", line 2275, in call\n      outputs = self.longformer(\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\", line 2224, in run_call_with_unpacked_inputs\n      version=1,\n    File \"/opt/conda/lib/python3.7/site-packages/transformers/models/longformer/modeling_tf_longformer.py\", line 1764, in call\n      embedding_output = self.embeddings(\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/transformers/models/longformer/modeling_tf_longformer.py\", line 571, in call\n      token_type_embeds = tf.gather(params=self.token_type_embeddings, indices=token_type_ids)\nNode: 'model/tf_longformer_for_question_answering_1/longformer/embeddings/Gather_2'\nindices[37,2809] = 1 is not in [0, 1)\n\t [[{{node model/tf_longformer_for_question_answering_1/longformer/embeddings/Gather_2}}]] [Op:__inference_train_function_195674]","output_type":"error"}]},{"cell_type":"code","source":"train_dataset = QADataset(train_data, tokenizer, max_seq_length)\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True,\n                               collate_fn=lambda batch: collate_fn(batch, device))","metadata":{"execution":{"iopub.status.busy":"2023-04-12T09:43:22.540081Z","iopub.execute_input":"2023-04-12T09:43:22.540830Z","iopub.status.idle":"2023-04-12T09:43:22.553075Z","shell.execute_reply.started":"2023-04-12T09:43:22.540790Z","shell.execute_reply":"2023-04-12T09:43:22.551518Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"train_dataloader.dataset[2]","metadata":{"execution":{"iopub.status.busy":"2023-04-12T09:52:07.908506Z","iopub.execute_input":"2023-04-12T09:52:07.908949Z","iopub.status.idle":"2023-04-12T09:52:07.928227Z","shell.execute_reply.started":"2023-04-12T09:52:07.908908Z","shell.execute_reply":"2023-04-12T09:52:07.926723Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([    2, 25751, 43691,  ...,     0,     0,     0]),\n 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]),\n 'token_type_ids': tensor([0, 0, 0,  ..., 0, 0, 0]),\n 'answer_start': tensor(0),\n 'answer_end': tensor(0)}"},"metadata":{}}]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2023-04-12T09:57:58.114658Z","iopub.execute_input":"2023-04-12T09:57:58.115107Z","iopub.status.idle":"2023-04-12T09:57:58.123615Z","shell.execute_reply.started":"2023-04-12T09:57:58.115064Z","shell.execute_reply":"2023-04-12T09:57:58.122049Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained('cointegrated/LaBSE-en-ru')\n# examples = QADataset.create_qa_examples(train_data, train_data)\n# questions = [example['context'] for example in examples]\n# question_tokens = [tokenizer.tokenize(question) for question in questions]\n# import matplotlib.pyplot as plt\n\n# question_lengths = [len(tokens) for tokens in question_tokens]\n# plt.hist(question_lengths, bins=50)\n# plt.xlabel('Length of question tokens')\n# plt.ylabel('Frequency')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-12T09:12:31.169678Z","iopub.execute_input":"2023-04-12T09:12:31.170101Z","iopub.status.idle":"2023-04-12T09:12:31.469158Z","shell.execute_reply.started":"2023-04-12T09:12:31.170062Z","shell.execute_reply":"2023-04-12T09:12:31.467823Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Разбиваем данные на обучающую и валидационную выборки\n# train_data, validation_data = train_test_split(train_data, test_size=0.2, random_state=42)\n# max_seq_length = 3072\n# model_name = \"allenai/longformer-large-4096-finetuned-triviaqa\"\n\n# # Число эпох обучения\n# num_epochs = 3\n# output_dir = 'my_model'","metadata":{"execution":{"iopub.status.busy":"2023-04-12T08:19:44.271339Z","iopub.execute_input":"2023-04-12T08:19:44.272315Z","iopub.status.idle":"2023-04-12T08:19:44.279790Z","shell.execute_reply.started":"2023-04-12T08:19:44.272266Z","shell.execute_reply":"2023-04-12T08:19:44.278474Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# 'cointegrated/LaBSE-en-ru'\n","metadata":{"execution":{"iopub.status.busy":"2023-04-12T05:01:27.596509Z","iopub.execute_input":"2023-04-12T05:01:27.596850Z","iopub.status.idle":"2023-04-12T05:01:27.612147Z","shell.execute_reply.started":"2023-04-12T05:01:27.596816Z","shell.execute_reply":"2023-04-12T05:01:27.611053Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# from transformers import BigBirdTokenizer, BigBirdForQuestionAnswering\n\n# tokenizer = BigBirdTokenizer.from_pretrained('google/bigbird-roberta-base')\n# model = BigBirdForQuestionAnswering.from_pretrained('google/bigbird-roberta-base')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-12T08:19:22.239844Z","iopub.status.idle":"2023-04-12T08:19:22.240924Z","shell.execute_reply.started":"2023-04-12T08:19:22.240629Z","shell.execute_reply":"2023-04-12T08:19:22.240658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# import tensorflow as tf\n\n# train(model_name, train_data, validation_data, output_dir)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T10:17:20.059711Z","iopub.status.idle":"2023-04-12T10:17:20.060101Z","shell.execute_reply.started":"2023-04-12T10:17:20.059905Z","shell.execute_reply":"2023-04-12T10:17:20.059923Z"},"trusted":true},"execution_count":null,"outputs":[]}]}