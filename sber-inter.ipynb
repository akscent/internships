{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":29296,"databundleVersionId":2344227,"sourceType":"competition"},{"sourceId":7709537,"sourceType":"datasetVersion","datasetId":4484528}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Импорт библиотек","metadata":{}},{"cell_type":"code","source":"# Для построения пайплайна обучения используется lightautoml, который конфликтуает с новой версией pandas. Поэтому\n!pip uninstall pandas -y\n!pip install --upgrade pip > installations.txt\n!pip uninstall torch -y > installations.txt # конфликтует \n!pip install torch==2.0.0 > installations.txt\n!pip install pandas==1.4.3 pyarrow yellowbrick polars transformers nltk gensim lightautoml > installations.txt\n!pip install --upgrade -q wandb > installations.txt","metadata":{"execution":{"iopub.status.busy":"2024-02-28T06:35:03.207997Z","iopub.execute_input":"2024-02-28T06:35:03.208723Z","iopub.status.idle":"2024-02-28T06:39:58.586965Z","shell.execute_reply.started":"2024-02-28T06:35:03.208672Z","shell.execute_reply":"2024-02-28T06:39:58.583979Z"},"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Found existing installation: pandas 2.2.0\nUninstalling pandas-2.2.0:\n  Successfully uninstalled pandas-2.2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.13 requires pandas, which is not installed.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.13 requires pandas, which is not installed.\nstable-baselines3 2.1.0 requires pandas, which is not installed.\ntorchaudio 2.1.2+cpu requires torch==2.1.2, but you have torch 2.0.0 which is incompatible.\ntorchtext 0.16.2+cpu requires torch==2.1.2, but you have torch 2.0.0 which is incompatible.\ntorchvision 0.16.2+cpu requires torch==2.1.2, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.0.11 which is incompatible.\nfeaturetools 1.28.0 requires pandas>=1.5.0, but you have pandas 1.4.3 which is incompatible.\nfitter 1.7.0 requires joblib<2.0.0,>=1.3.1, but you have joblib 1.2.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nplotnine 0.12.4 requires pandas>=1.5.0, but you have pandas 1.4.3 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.4.3 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nxarray 2024.1.0 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nxarray 2024.1.0 requires pandas>=1.5, but you have pandas 1.4.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# for dataframe\nimport polars as pl\nimport numpy as np\nimport pyarrow as pa\nimport pandas as pd\n\n# for system\nimport os\nimport time\nimport requests\nimport sys\n\n# for metric\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\n\n# for demention decrease\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\n\n# for common functions\nfrom collections import OrderedDict\nfrom collections import Counter\nfrom kaggle_secrets import UserSecretsClient\nfrom copy import deepcopy as copy\nfrom typing import Tuple, List\n\n# for monitoring of models\nimport wandb\nfrom wandb.keras import WandbCallback\n\n# for machine learning\nimport torch.nn as nn\nimport torch\nfrom lightautoml.ml_algo.tuning.optuna import OptunaTuner\nfrom lightautoml.reader.base import PandasToPandasReader\nfrom lightautoml.tasks import Task\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.report.report_deco import ReportDeco\n\n# my functions\nsys.path.append('/kaggle/input/next-orders')\nimport my_functions","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-28T06:39:58.591584Z","iopub.execute_input":"2024-02-28T06:39:58.592522Z","iopub.status.idle":"2024-02-28T06:40:52.234657Z","shell.execute_reply.started":"2024-02-28T06:39:58.592463Z","shell.execute_reply":"2024-02-28T06:40:52.233448Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/sbermarket-internship-competition/sample_submission.csv\n/kaggle/input/sbermarket-internship-competition/train.csv\n/kaggle/input/next-orders/Train (1).parquet\n/kaggle/input/next-orders/s_Train.parquet\n/kaggle/input/next-orders/s_Test.parquet\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Препроцессинг данных\n\n____________________________________________________\nИспользовался ноутбук с TPU и RAM 300GB, чтобы не испытывать проблем с памятью во время операционных обработок датасета.","metadata":{}},{"cell_type":"code","source":"# tmp импорт в pandas\nraw = pd.read_csv('../input/sbermarket-internship-competition/train.csv')\nsub = pd.read_csv('../input/sbermarket-internship-competition/sample_submission.csv', sep = \",\")\n\n# Приведение столбца 'cart' к int\nraw['cart'] = raw['cart'].astype(int)\n\n# Отбрасываем выбросы - юзеров с малым количеством товаров в истории их заказов\nfiltered_raw, filtered_sub, proportion = filter_raw_data(raw, sub)\nprint(f\"Процент наблюдений, используемый для тренировки: {proportion:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-02-28T13:16:33.801767Z","iopub.execute_input":"2024-02-28T13:16:33.802384Z","iopub.status.idle":"2024-02-28T13:16:37.131991Z","shell.execute_reply.started":"2024-02-28T13:16:33.802344Z","shell.execute_reply":"2024-02-28T13:16:37.130475Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"### Polars ускоряет обработку данных\n__________________________________________________\nВ итоге мы получаем pd датафрейм с усредненным рейтингом id во всем датасете и набор временных переменных, основанных на этой метрике (рейтинг)","metadata":{}},{"cell_type":"code","source":"%%time\n# filtered_raw = pl.from_pandas(filtered_raw)\ntrain_raw = ohe_data(filtered_raw)\ntrain_data = full_history(train_raw)\nTrain = create_dataset(train_data)\n\n# filtered_sub = pl.from_pandas(filtered_sub)\ntest_sub = ohe_data(filtered_sub)\ntest_data= full_history(test_sub)\nTest = create_dataset(test_data, history_flag = 1)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-28T05:58:08.820444Z","iopub.execute_input":"2024-02-28T05:58:08.820714Z","iopub.status.idle":"2024-02-28T05:59:12.935158Z","shell.execute_reply.started":"2024-02-28T05:58:08.820681Z","shell.execute_reply":"2024-02-28T05:59:12.934014Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_13/85236963.py:82: DeprecationWarning: `apply` is deprecated. It has been renamed to `map_elements`.\n  order_number_df = order_number_df.with_columns(pl.col(\"order_number\").apply(lambda x: x + 1))\n/tmp/ipykernel_13/85236963.py:82: PolarsInefficientMapWarning: \nExpr.map_elements is significantly slower than the native expressions API.\nOnly use if you absolutely CANNOT implement your logic otherwise.\nReplace this expression...\n  - pl.col(\"order_number\").map_elements(lambda x: ...)\nwith this one instead:\n  + pl.col(\"order_number\") + 1\n\n  order_number_df = order_number_df.with_columns(pl.col(\"order_number\").apply(lambda x: x + 1))\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 8min 32s, sys: 2min 49s, total: 11min 22s\nWall time: 1min 4s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### X / Y ","metadata":{}},{"cell_type":"code","source":"x_cols = Train.select_dtypes(include=['int', 'int8', 'int32', 'uint32', 'uint8', 'float']).drop(columns = ['target'], axis = 1).columns.tolist()\nx_cols_pca = Train.select_dtypes(include=['int', 'int8', 'int32', 'uint32', 'uint8', 'float']).drop(columns = ['user_id', 'target'], axis = 1).columns.tolist()\nprint(x_cols)\ny_cols = ['target']\nprint(y_cols)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T07:41:58.835202Z","iopub.execute_input":"2024-02-28T07:41:58.835723Z","iopub.status.idle":"2024-02-28T07:42:08.460945Z","shell.execute_reply.started":"2024-02-28T07:41:58.835687Z","shell.execute_reply":"2024-02-28T07:42:08.458940Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"['user_id', 'hour_mean', 'hour_max', 'hour_min', 'hour_std', 'week_mean', 'week_max', 'week_min', 'week_std', 'weekday_mean', 'weekday_max', 'weekday_min', 'weekday_std', 'day_mean', 'day_max', 'day_min', 'day_std', 'month_mean', 'month_max', 'month_min', 'month_std', 'year_mean', 'year_max', 'year_min', 'year_std', 'total_rating_mean', 'total_rating_max', 'total_rating_min', 'total_rating_std', 'ordered_mean', 'ordered_max', 'ordered_min', 'ordered_std', 'total_order_in_cat_mean', 'total_order_in_cat_max', 'total_order_in_cat_min', 'total_order_in_cat_std', 'total_order_num_mean', 'total_order_num_max', 'total_order_num_min', 'total_order_num_std', 'rating_per_m_mean', 'rating_per_m_std', 'rating_per_m_sum', 'rating_per_m_median', 'rating_per_w_mean', 'rating_per_w_std', 'rating_per_w_sum', 'rating_per_w_median', 'rating_per_d_mean', 'rating_per_d_std', 'rating_per_d_sum', 'rating_per_d_median', 'rating_per_hour_mean', 'rating_per_hour_std', 'rating_per_hour_sum', 'rating_per_hour_median', 'pc1', 'pc2', 'pc3', 'pc4', 'pc5', 'pc6', 'pc7', 'pc8', 'pc9', 'pc10', 'Clusters']\n['target']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Добавляем главные компоненты","metadata":{}},{"cell_type":"code","source":"scaler = RobustScaler()\n\ns_Train = Train.copy()\ns_Test = Test.copy()\ns_Train[x_cols_pca] = scaler.fit_transform(s_Train[x_cols_pca])\ns_Test[x_cols_pca] = scaler.transform(s_Test[x_cols_pca])\n\npca = PCA(n_components=10)\n\ns_Train_pca = pca.fit_transform(s_Train[x_cols])\ns_Test_pca = pca.transform(s_Test[x_cols])\n\nTrain_pca = pd.DataFrame(s_Train_pca, columns=[f'pc{i+1}' for i in range(s_Train_pca.shape[1])])\nTest_pca = pd.DataFrame(s_Test_pca, columns=[f'pc{i+1}' for i in range(s_Train_pca.shape[1])])\n\ns_Train[Train_pca.columns.to_list()] = Train_pca\ns_Test[Test_pca.columns.to_list()] = Test_pca","metadata":{"execution":{"iopub.status.busy":"2024-02-28T06:02:17.059805Z","iopub.execute_input":"2024-02-28T06:02:17.060318Z","iopub.status.idle":"2024-02-28T06:04:32.090345Z","shell.execute_reply.started":"2024-02-28T06:02:17.060278Z","shell.execute_reply":"2024-02-28T06:04:32.088155Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Кластеризация id(юзер-категория)","metadata":{}},{"cell_type":"code","source":"print('Elbow Method to determine the number of clusters to be formed:')\nwarnings.filterwarnings(\"ignore\", message=\"findfont:.*\")\nElbow_M = KElbowVisualizer(KMeans(), k=21)\nElbow_M.fit(Train_pca.drop(columns = ['id', 'target'], axis = 1))\nElbow_M.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:27:05.754715Z","iopub.status.idle":"2024-02-27T02:27:05.755537Z","shell.execute_reply.started":"2024-02-27T02:27:05.755068Z","shell.execute_reply":"2024-02-27T02:27:05.755093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Сохранение данных в parquet","metadata":{}},{"cell_type":"code","source":"# Train.to_parquet('Train.parquet', index=False)\n# s_Train.to_parquet('s_Train.parquet', index=False)\n# s_Test.to_parquet('s_Test.parquet', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T06:08:24.239364Z","iopub.execute_input":"2024-02-28T06:08:24.239723Z","iopub.status.idle":"2024-02-28T06:09:09.864831Z","shell.execute_reply.started":"2024-02-28T06:08:24.239686Z","shell.execute_reply":"2024-02-28T06:09:09.863730Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"s_Train = pd.read_parquet('/kaggle/input/next-orders/s_Train.parquet')\ns_Test = pd.read_parquet('/kaggle/input/next-orders/s_Test.parquet')","metadata":{"execution":{"iopub.status.busy":"2024-02-28T12:29:30.863539Z","iopub.execute_input":"2024-02-28T12:29:30.865316Z","iopub.status.idle":"2024-02-28T12:30:06.519240Z","shell.execute_reply.started":"2024-02-28T12:29:30.865251Z","shell.execute_reply":"2024-02-28T12:30:06.518045Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"## LightAutoML пайплайн\n","metadata":{}},{"cell_type":"code","source":"Train_set, Valid_set = train_test_split(Train, test_size = TEST_SIZE,\n                                        stratify = None, random_state = 23)\nTrain_set.reset_index(drop=True, inplace=True)\nValid_set.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T06:41:11.858935Z","iopub.execute_input":"2024-02-28T06:41:11.860073Z","iopub.status.idle":"2024-02-28T06:41:31.235344Z","shell.execute_reply.started":"2024-02-28T06:41:11.860024Z","shell.execute_reply":"2024-02-28T06:41:31.233413Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def f1 (real, pred, **kwargs):\n    return f1_score(real, (pred > 0.2).astype(int), **kwargs)\n\nN_THREADS = 2\nN_FOLDS = 5\nRANDOM_STATE = 42\nTEST_SIZE = 0.2\nTARGET_NAME = 'target'\nROLES = {'target': TARGET_NAME, 'drop': ['id', 'user_id', 'category'], 'category': ['Clusters']}\nTASK = Task('binary', metric = f1)\n\nreader = PandasToPandasReader(TASK, cv=N_FOLDS, random_state=RANDOM_STATE)\n\nlama_params = {\n    \"task\": TASK,\n    \"cpu_limit\": N_THREADS,\n    \"reader_params\": {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE}\n}\ndefault_nn_params = {\n    \"bs\": 128, \"num_workers\": 0, \"path_to_save\": None, \"n_epochs\": 1, \"freeze_defaults\": True\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-02-28T06:41:31.252509Z","iopub.execute_input":"2024-02-28T06:41:31.253028Z","iopub.status.idle":"2024-02-28T06:41:31.276710Z","shell.execute_reply.started":"2024-02-28T06:41:31.252986Z","shell.execute_reply":"2024-02-28T06:41:31.274842Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Weight and Biasses мониторинг моделей","metadata":{}},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"wandb_api\") \n\nwandb.login(key=wandb_api)\nwandb.login()\n\nCONFIG = dict (\n    lama_params,\n    general_params = {\"use_algos\": [[\"linear_12\", \"lgbm\", \"denselight\"]]},\n    tuning_params = {'max_tuning_iter': 20},\n    lgb_params = {'default_params': {'num_threads': N_THREADS}},\n    nn_params={**default_nn_params,'lr': 0.03},\n    infra = \"Kaggle\",\n    competition = 'plant-pathology',\n    _wandb_kernel = 'ayut'\n)\nCONFIG['model_name'] = 'lightAutoML-experiments_w_features_1'\nrun = wandb.init(project='sber-inter', \n                 config=CONFIG,\n                 group='lightAutoML', \n                 job_type='train')\n\nwandb.config.type = 'lightAutoML'\nwandb.config.kaggle_competition = 'SberMarket Competition'","metadata":{"execution":{"iopub.status.busy":"2024-02-28T06:41:31.281075Z","iopub.execute_input":"2024-02-28T06:41:31.281589Z","iopub.status.idle":"2024-02-28T06:41:48.783724Z","shell.execute_reply.started":"2024-02-28T06:41:31.281541Z","shell.execute_reply":"2024-02-28T06:41:48.782328Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2024-02-28 06:41:34.030900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-28 06:41:34.031150: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-28 06:41:34.212133: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mirinyakov2016\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"%%time \n\n# наиболее оптимальный на данный момент пайплайн\nautoml = TabularUtilizedAutoML(\n    task = TASK,\n    timeout = 3600*3,\n    cpu_limit = N_THREADS,\n    reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n)\n\n# выбранные среди всех наиболее значимые переменные\ntrain_pred = automl.fit_predict(Train_set[['total_order_in_cat_max',\n 'ordered_mean',\n 'pc2',\n 'weekday_std',\n 'pc9',\n 'pc10',\n 'category',\n 'pc4',\n 'pc5',\n 'pc6',\n 'month_std',\n 'pc3',\n 'week_std',\n 'hour_std',\n 'hour_mean',\n 'pc1',\n 'pc7', 'target']], roles = ROLES, verbose = 2)\n\nprint('Score', \"%.5f\" % f1(Train_set.target, train_pred.data))\nvalid_pred = automl.predict(Valid_set[['total_order_in_cat_max',\n 'ordered_mean',\n 'pc2',\n 'weekday_std',\n 'pc9',\n 'pc10',\n 'category',\n 'pc4',\n 'pc5',\n 'pc6',\n 'month_std',\n 'pc3',\n 'week_std',\n 'hour_std',\n 'hour_mean',\n 'pc1',\n 'pc7', 'target']])\nprint('Score on out of folds validation', \"%.5f\" % f1(Valid_set.target, valid_pred.data))\n# best catboost params \n# {'task_type': 'CPU', 'thread_count': 4, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.009044636094268511, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 4, 'min_data_in_leaf': 7, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n# best linear\n#\n# best lgbm \n# {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 105, 'feature_fraction': 0.8625799184703501, 'bagging_fraction': 0.5053328530427746, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 7.265259184516205e-05, 'reg_lambda': 0.621571500507215, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 4, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'min_sum_hessian_in_leaf': 4.636375055852895}\n# best denselight\n# {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': 'cpu', 'use_cont': True, 'use_cat': True, 'use_text': False, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'denselight', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 30, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 10, 'swa': True}, 'bs': 1024, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': 'Adam', 'opt_params': {'lr': 0.003757084358753148, 'weight_decay': 0}, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'patience': 5, 'factor': 0.5, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': 'UniversalDataset', 'tuned': True, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': True, 'n_out': None, 'hid_factor': [2, 2], 'hidden_size': [512, 256], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': 'LeakyReLU', 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 50, 'max_tuning_time': 3600}}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T09:42:08.807426Z","iopub.execute_input":"2024-02-28T09:42:08.809433Z","iopub.status.idle":"2024-02-28T12:05:31.867649Z","shell.execute_reply.started":"2024-02-28T09:42:08.809307Z","shell.execute_reply":"2024-02-28T12:05:31.865222Z"},"_kg_hide-output":true,"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"[09:42:10] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n[09:42:10] - time: 10800.00 seconds\n[09:42:10] - CPU: 2 cores\n[09:42:10] - memory: 16 GB\n\n[09:42:10] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n\n[09:42:10] ==================================================\n[09:42:10] Start 0 automl preset configuration:\n[09:42:10] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n[09:42:10] Stdout logging level is INFO2.\n[09:42:10] Task: binary\n\n[09:42:10] Start automl preset with listed constraints:\n[09:42:10] - time: 10799.99 seconds\n[09:42:10] - CPU: 2 cores\n[09:42:10] - memory: 16 GB\n\n[09:42:10] \u001b[1mTrain data shape: (7871147, 18)\u001b[0m\n\n[09:42:30] Layer \u001b[1m1\u001b[0m train process start. Time left 10779.81 secs\n[09:56:41] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n[09:56:42] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[09:57:22] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[09:58:01] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[09:58:39] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[09:59:31] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n[10:00:13] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.4229517894114167\u001b[0m\n[10:00:13] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n[10:00:13] Time left 9717.03 secs\n\n[10:15:19] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n[10:15:20] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[10:23:30] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n[10:32:38] Time limit exceeded after calculating fold 1\n\n[10:32:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.43306053412012774\u001b[0m\n[10:32:40] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n[10:32:40] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n[10:57:36] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n[10:57:36] The set of hyperparameters \u001b[1m{'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}\u001b[0m\n achieve 0.4400 AutoML Metric\n[10:57:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n[10:57:38] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n[12:03:39] Time limit exceeded after calculating fold 0\n\n[12:03:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.4314999542417864\u001b[0m\n[12:03:40] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n[12:03:40] Time left 2309.67 secs\n\n[12:03:40] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n\n[12:03:40] \u001b[1mLayer 1 training completed.\u001b[0m\n\n[12:03:44] Blending: optimization starts with equal weights and score \u001b[1m0.4273008033737062\u001b[0m\n[12:04:40] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.43364984578543336\u001b[0m, weights = \u001b[1m[0.         0.7016421  0.29835787]\u001b[0m\n[12:05:31] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.43364984578543336\u001b[0m, weights = \u001b[1m[0.         0.7016421  0.29835787]\u001b[0m\n[12:05:31] Blending: no score update. Terminated\n\n[12:05:31] \u001b[1mAutoml preset training completed in 8601.33 seconds\u001b[0m\n\n[12:05:31] Model description:\nFinal prediction for new objects (level 0) = \n\t 0.70164 * (2 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n\t 0.29836 * (1 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n\n[12:05:31] ==================================================\nCPU times: user 3h 51min 50s, sys: 2min 34s, total: 3h 54min 24s\nWall time: 2h 23min 23s\n","output_type":"stream"}]},{"cell_type":"code","source":"# fast_fi = automl.get_feature_scores('fast', silent=False)\n# fast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (30, 10), grid = True)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:31:49.237082Z","iopub.execute_input":"2024-02-28T16:31:49.238683Z","iopub.status.idle":"2024-02-28T16:31:49.280149Z","shell.execute_reply.started":"2024-02-28T16:31:49.238538Z","shell.execute_reply":"2024-02-28T16:31:49.278580Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import joblib\n\njoblib.dump(automl, 'automl_02.pkl')\n# automl=joblib.load('/kaggle/input/next-orders/automl_rd.pkl')\n\nrun = wandb.init(project='sber-inter', \n                 config=CONFIG,\n                 group='lightAutoML', \n                 job_type='save_experiment')\n\nwandb.config.type = 'lightAutoML'\nwandb.config.kaggle_competition = 'SberMarket Competition'\n\nartifact = wandb.Artifact(name='automl', type='model')\nartifact.add_file('/kaggle/working/automl_01.pkl')\nrun.log_artifact(artifact)\n\nrun.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Нахождение лучшего порогового значения для сепарации 0 и 1","metadata":{}},{"cell_type":"code","source":"best_score = 0\nfor i in np.arange(0.01, 1.0, 0.01):\n    score = f1 = f1_score(Valid_set.target, (valid_pred.data > i).astype(int))\n    if score > best_score:\n        best_score = score\n        proba_split = i\n\nprint('At i =', \"%.2f\" % proba_split,'score is : ' \"%.5f\" % best_score)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T13:31:52.329631Z","iopub.execute_input":"2024-02-28T13:31:52.330228Z","iopub.status.idle":"2024-02-28T13:33:07.257690Z","shell.execute_reply.started":"2024-02-28T13:31:52.330185Z","shell.execute_reply":"2024-02-28T13:33:07.255406Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"At i = 0.21 score is : 0.43842\n","output_type":"stream"}]},{"cell_type":"code","source":"s_Test['target'] = (predictions.data > proba_split).astype(int)\nsubmit = pd.merge(sub['id'], s_Test[['id', 'target']], on='id')","metadata":{"execution":{"iopub.status.busy":"2024-02-28T13:33:07.332204Z","iopub.execute_input":"2024-02-28T13:33:07.332629Z","iopub.status.idle":"2024-02-28T13:33:27.038177Z","shell.execute_reply.started":"2024-02-28T13:33:07.332593Z","shell.execute_reply":"2024-02-28T13:33:27.035955Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"## Подготовка сабмита","metadata":{}},{"cell_type":"code","source":"import csv\n\nwith open('submission02.csv', 'w', newline='') as csvfile:\n    csvwriter = csv.writer(csvfile)\n    csvwriter.writerow(submit.columns)\n    for row in submit.values:\n        csvwriter.writerow(row)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T13:33:27.041904Z","iopub.execute_input":"2024-02-28T13:33:27.042413Z","iopub.status.idle":"2024-02-28T13:33:29.135951Z","shell.execute_reply.started":"2024-02-28T13:33:27.042376Z","shell.execute_reply":"2024-02-28T13:33:29.134358Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}